{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.vectorstores.base import VectorStoreRetriever\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import ChatGLM\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory, ConversationBufferWindowMemory\n",
    "import pickle\n",
    "from langchain.document_loaders import JSONLoader\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"vector_src/mh_src-vectorstore.pkl\"\n",
    "with open(db_path, 'rb') as f:\n",
    "    db = pickle.load(f)\n",
    "# retriever = VectorStoreRetriever(vectorstore=db)\n",
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={'k': 10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相关关键词2023/10/29雷雨天气条件下保障航空飞行安全的有效措施-中国期刊网https:///thesis/view/47660611/3\n",
      "民航安全一直是我国当局的工作重心，现代飞机航电系统交联关系复杂，系统高度集成，惯导系统又是高度精密的设备，其与飞机上的其他各项设备关联功能的完整性任需加强。\n",
      "编号南京航空航天大学毕业论文题目气象条件对于民航飞行安全的影响学生姓名奚晓迪学号070850605学院民航飞行学院专业飞行技术班级0708506指导教师陆中教授二零一叁年伍月贰拾日\n",
      "首页期刊导航论文中心期刊检索论文检索新闻中心恶劣天气对飞行安全的影响柴栋梁中国东方航空公司山西分公司山西省太原市030031摘要：恶劣天气对飞行安全的影响是巨大和致命性的，包括大风、云层、气压、气温、大气密度、雷电、冰雪等在内的恶劣天气均会对飞行安全产生极大的危害，严重时会引发空难。鉴于恶劣天气会导致飞行安全的控制工作遇到诸多的难题，因而一直以来航空公司均可以给予飞行安全高度的重视，这也是航空公司一直研究的重点问题。本文先对飞机安全飞行的重要性作简要分析，进而重点分析探究大风、云层、雷电、冰雪、雷雨、结冰对飞行安全的影响，最后提出降低恶劣天气对飞行安全的影响，确保飞行安全的策略。关键词：恶劣天气；飞行安全；气象环境天气是地球对动力、辐射、电能、水汽、气压的精巧平衡，之所以飞机飞行时格外注重天气因素，其原因就在于恶劣的天气会直接导致飞机处于极度危险的境地。每年因为恶劣天气所导致的民航事故可以占到总事故的四分之一到二分之一，每年因为恶劣天气所导致的航班延误和事故损失可以达到10亿美元以上。由此可以看出，恶劣天气对飞行\n",
      "首页期刊导航论文中心期刊检索论文检索新闻中心浅谈雷雨天气下民航飞行特点张芸民航贵州空管分局摘要：众所周知，民航在飞行时会受到天气和民航动能等多方面因素的影响，无形中加大民航飞行时出现安全事故的可能。而雷雨天气作为民航飞行时经常遇到的天气状况，在这种天气状况条件下对流层中大气运行稳定性较差，造成民航飞行稳定性下降，这对于民航飞行安全效果也有很大的影响。本文将对雷雨天气综合分析，并根据分析结果概述雷雨天气下民航飞行特点。关键词：雷雨天气；民航飞行；特点引言与其他交通工具相比，民航飞行高度多半在对流层这一高度范围内。这就导致民航飞行时经常会受到恶劣天气的干扰，造成民航飞行安全性下降，难以满足民航飞行安全要求。据不完全数据统计，民航在飞行过程中因雷电天气而出现的安全事故在所有安全事故当中占据极高的比重。这就应加强雷电电气的分析力度，同时深入研究雷电天气民航飞行特点。据此制定合理措施，控制雷电天气对民航飞行产生的影响。1雷电天气由于雷电天气对民航飞行安全效果有一定影响，这就应加强雷电天气分析力度，借以保证相关人员对雷电天气特\n",
      "息的通知流程。值班前，管制员要做好充分的工作，事先到自己的位置，充分掌握雷达图，熟悉当前的气象条件，准确牢记流量控制、空军活动等方面的需求，并随时观察交接管制员的控制和指挥工作，及时落实岗前准备，以保障飞机飞行安全。23加大对天气的观察力度并及时上报其中管制员需要对飞行中飞机的实时情况进行管制和指挥，应及时向上级领导汇报所有飞机在飞行中的天气情况和飞行情况。如果遇到极端恶劣天气时，飞行员或偏离预先设计出的飞行方案，此时需要管制员实时关注飞行方向，并随时与飞行员进行沟通，确保能够收集到飞机在每一时间内的具体位置信息，在对飞机飞行位置进行深入分析后，需要再次确定出在雷雨天气下的飞行方案，并及时告知飞行员，调整飞行速度、方向、位置等，最终来保证飞机教学与研究2022年13期首页>《教学与研究》>2022年13期>雷雨天气中电击对飞行的影响及对策请输入关键词期刊（整期优先）网络出版时间：2022-10-20作者:耿海周新辉文化科学>教育学分享打印同系列资源1/2来源期刊\n",
      "打印同系列资源1/2来源期刊雷雨天气对飞机飞行的影响及安全管控浅谈雷雨天气下民航飞行特点探析雷雨天气对民航航班的影响与优化对策雷雨天气条件下保障航空飞行安全的有效措施雷雨天气对民航通信导航监视设备的影响及保障措施相关推荐同分类资源更多[教育学]小学低年级语文汉字教学问题探究[教育学]新课程下的农村高中英语课堂教学[教育学]从生活中来，回数学中去[教育学]如何通过阅读提高英语写作能力[教育学]读者寄来的难题雷雨天气电击飞行影响对策相关关键词2023/10/29雷雨天气中电击对飞行的影响及对策-中国期刊网https:///thesis/view/65267251/3\n",
      "在雷暴区起飞和降落，则要高度重视低空风切变的影响，充分确保飞行安全。结语各类恶劣天气对飞机飞行的安全性有很大的影响，为确保飞行的安全性，必须对影响飞机安全飞行的恶劣天气做到针对性预防，尽量避免在恶劣天气时飞行。为很好的提升飞行安全，要重点做好强化气象预测能力、提升飞行员的综合素养、加强恶劣天气下的飞行管制力度单方面的工作。参考文献[1]李纯柱非常规天气下航空器飞行的改航策略研究[J]中国民航大学学报,2020,38(05):5-9[2]李浩一次雷雨天气过程分析及对飞行的影响[J]南方农机,2020,51(01):233[3]郑洁试论区域性复杂天气对民航飞机起降的影响及保障措施[J]科技创新导报,2020,17(07):4+6同系列内容查看全部《科学与技术》2021年05期-新时期国有企业财务管理信息化建设的思考2021-07-231《科学与技术》2021年05期-机电工程等电位联结作用及施工质量控制2021-07-232《科学与技术》2021年05期-建筑暖通工程的施工质量管理与控制2021-07-233《科学与技术》2021年05期-关于土木工程建筑施工技术创新研究2021-07-234《科学与技术》2021年05期-水源热泵在空调系统中的应用2021-07-235关于我们\n",
      "若发现您的权益受到侵害，请立即联系客服QQ(30444492)或邮箱()，我们会尽快为您处理版权所有©2002-2023期刊网()琼ICP备号2023/10/29恶劣天气对飞行安全的影响-中国期刊网https:///thesis/view/52195303/3\n",
      "安全的影响是十分巨大的，若飞行过程中遇到恶劣天气，对飞机和乘客的安全有极大的威胁。基于此，充分明确和掌握恶劣天气对飞行安全的影响，并做好安全飞行工作尤为关键，必须给予高度重视。飞机安全飞行的重要性随着近年来航空事业的发展，飞机越来越成为人们出行的首选方式之一，可以满足人们出行的需要。基于人们对飞机安全飞行的高度重视，飞机飞行安全一直以来都被航空事业视为发展的核心，这很大程度上提升了飞机飞行的安全性[1]。就飞机安全飞行的重要性来说，安全是飞行的生命线，不可忽视，更不能有一丝丝的放松，只有当拥有安全时才可以拥有一切。虽然事故率是所有交通工具中最低的，但也存在一定的风险性，一旦飞行过程中恶劣天气和其他原因，极易引发事故，导致人员伤亡。为保证飞机飞行的绝对安全，必须掌握飞机飞行过程中的一切风险因素，并做好预防性工作。尤其是要建立安全意识，培养全员的安全意识，比如要培养飞行员遵纪守法和按章办事的飞行作风，确保可以严格按照操作流程完成飞行。另外，要加强飞机安全飞行的执行能力，做好监督检查工作，确保飞机飞行有充分的安全性。需要清楚认识到一\n",
      "3043\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(query=\"电天气下民航飞机的飞行风险及预防措施分析中的国内外研究进展有哪些?\")\n",
    "content = \"\\n\".join([doc.page_content for doc in docs])\n",
    "print(content)\n",
    "print(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 在分析雷电天气下民航飞机的飞行风险及预防措施时，研究背景主要是对话册中提到的气象条件对飞行安全的影响。文章指出，恶劣天气，如大风、云层、雷电、冰雪等，均会对飞行安全产生极大的危害，严重时可能引发空难。因此，研究这些天气条件对飞行安全的影响以及采取有效的预防措施，对于确保飞行安全具有重要的实际意义。"
     ]
    }
   ],
   "source": [
    "from gc import set_debug\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.globals import set_verbose\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from query_data import get_llm\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "set_verbose(True)\n",
    "set_verbose(True)\n",
    "set_debug(True)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    openai_api_base=\"http://localhost:8000/v1\",\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    max_tokens=8000,\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "# llm = ChatOpenAI(\n",
    "#     openai_api_base=\"https://aiapi.xing-yun.cn/v1\",\n",
    "#     openai_api_key=\"sk-3e5wTBAl2iFDvQvW9b5693C90a97425eBf3b4bEa558eC66a\",\n",
    "#     temperature=0.1,\n",
    "#     model_name=\"gpt-3.5-turbo\",\n",
    "#     streaming=True,  # ! important\n",
    "#     callbacks=[StreamingStdOutCallbackHandler()]  # ! important\n",
    "# )\n",
    "# 你一定要根据提供的<context>的基础上回答。多引用背景材料, 对每一个例子都要有具体的分析, 避免出现总结性的语句.如果出现相关的数据,作者名,文章名,必须要全部引用出来 .不能漏掉. \n",
    "# 如果您不知道答案,只需说“嗯,我不确定”。不要试图编造答案。\n",
    "# 写作风格符合常见的中文学术写作风格。要包函<context>中的所有内容.\n",
    "template_zh = \"\"\"\n",
    "### Instruction ###\n",
    "Take deep and think step by step.\n",
    "您是一个信息提取助手,能够根据下面<context>中的所有信息,提取出和用户提出的问题相关联的所有人名.\n",
    "<context>\n",
    "背景: {context}\n",
    "<context/>\n",
    "用中文输出.不少于500字\n",
    "\"\"\"\n",
    "\n",
    "question = \"雷电天气下民航飞机的飞行风险及预防措施分析中研究背景是什么?\"\n",
    "# context = \"在雷电天气下，民航飞机的飞行面临着一定的风险。为了确保飞行安全，需要对雷电天气下的飞行风险进行分析，并制定相应的预防措施。本研究旨在探讨雷电天气对民航飞机飞行的影响，并研究相关的飞行风险和预防措施。\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=template_zh)\n",
    "# model = ConversationChain(llm=llm)\n",
    "# model = get_llm('local')\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template_zh),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = ANSWER_PROMPT | llm | StrOutputParser()\n",
    "\n",
    "# print(content)\n",
    "output = chain.invoke({\"context\":content, \"question\": question})\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(callbacks=[<langchain.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x7f210b6296d0>], client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.1, openai_api_key='EMPTY', openai_api_base='http://localhost:8000/v1', openai_organization='', openai_proxy='', streaming=True, max_tokens=8000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llm('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humanhi, ai:AIMessage\n",
      "[HumanMessage(content='hi'), AIMessage(content='AIMessage')]\n",
      "humanhi, ai:AIMessage\n",
      "[HumanMessage(content='hi'), AIMessage(content='AIMessage')]\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-FL5W5***************************************SRgJ. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/dell/Project/chat-your-data/test_prompt.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dell/Project/chat-your-data/test_prompt.ipynb#W6sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m chain \u001b[39m=\u001b[39m _inputs \u001b[39m|\u001b[39m ANSWER_PROMPT \u001b[39m|\u001b[39m llm \u001b[39m|\u001b[39m StrOutputParser()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dell/Project/chat-your-data/test_prompt.ipynb#W6sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m chat_history \u001b[39m=\u001b[39m [(\u001b[39m\"\u001b[39m\u001b[39mhi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhello\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dell/Project/chat-your-data/test_prompt.ipynb#W6sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m answer \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dell/Project/chat-your-data/test_prompt.ipynb#W6sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     {\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dell/Project/chat-your-data/test_prompt.ipynb#W6sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m\"\u001b[39;49m:question,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dell/Project/chat-your-data/test_prompt.ipynb#W6sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mchat_history\u001b[39;49m\u001b[39m\"\u001b[39;49m:[(\u001b[39m\"\u001b[39;49m\u001b[39mhi\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mAIMessage\u001b[39;49m\u001b[39m\"\u001b[39;49m)]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dell/Project/chat-your-data/test_prompt.ipynb#W6sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     }\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/dell/Project/chat-your-data/test_prompt.ipynb#W6sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/schema/runnable/base.py:1153\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1153\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1154\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1155\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1156\u001b[0m             patch_config(\n\u001b[1;32m   1157\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1158\u001b[0m             ),\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[1;32m   1160\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/schema/runnable/base.py:2505\u001b[0m, in \u001b[0;36mRunnableBinding.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m   2500\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2501\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   2502\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2503\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2504\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[0;32m-> 2505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   2506\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   2507\u001b[0m         merge_configs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig, config),\n\u001b[1;32m   2508\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs},\n\u001b[1;32m   2509\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/schema/runnable/base.py:1664\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   1652\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   1653\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m   1654\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1662\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1663\u001b[0m         ]\n\u001b[0;32m-> 1664\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;49;00m key, future \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(steps, futures)}\n\u001b[1;32m   1665\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/schema/runnable/base.py:1664\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   1652\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   1653\u001b[0m             executor\u001b[39m.\u001b[39msubmit(\n\u001b[1;32m   1654\u001b[0m                 step\u001b[39m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1662\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1663\u001b[0m         ]\n\u001b[0;32m-> 1664\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   1665\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/schema/runnable/base.py:1153\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1153\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1154\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1155\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1156\u001b[0m             patch_config(\n\u001b[1;32m   1157\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1158\u001b[0m             ),\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[1;32m   1160\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/schema/runnable/branch.py:185\u001b[0m, in \u001b[0;36mRunnableBranch.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     expression_value \u001b[39m=\u001b[39m condition\u001b[39m.\u001b[39minvoke(\n\u001b[1;32m    177\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m    178\u001b[0m         config\u001b[39m=\u001b[39mpatch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m         ),\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    184\u001b[0m     \u001b[39mif\u001b[39;00m expression_value:\n\u001b[0;32m--> 185\u001b[0m         output \u001b[39m=\u001b[39m runnable\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m    186\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    187\u001b[0m             config\u001b[39m=\u001b[39;49mpatch_config(\n\u001b[1;32m    188\u001b[0m                 config,\n\u001b[1;32m    189\u001b[0m                 callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(tag\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbranch:\u001b[39;49m\u001b[39m{\u001b[39;49;00midx\u001b[39m \u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    190\u001b[0m             ),\n\u001b[1;32m    191\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    192\u001b[0m         )\n\u001b[1;32m    193\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/schema/runnable/base.py:1153\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1153\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1154\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1155\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1156\u001b[0m             patch_config(\n\u001b[1;32m   1157\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1158\u001b[0m             ),\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[1;32m   1160\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/chat_models/base.py:142\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    133\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    138\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[1;32m    139\u001b[0m     config \u001b[39m=\u001b[39m config \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\n\u001b[1;32m    141\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 142\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    143\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    144\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    145\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    146\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    147\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    148\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    149\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    150\u001b[0m         )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[1;32m    151\u001b[0m     )\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/chat_models/base.py:459\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    452\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    453\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    457\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    458\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/chat_models/base.py:349\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    348\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 349\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    350\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    351\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[1;32m    352\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    353\u001b[0m ]\n\u001b[1;32m    354\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/chat_models/base.py:339\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    337\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 339\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    340\u001b[0m                 m,\n\u001b[1;32m    341\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    342\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    343\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    344\u001b[0m             )\n\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    347\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/chat_models/base.py:492\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    489\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 492\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    493\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    494\u001b[0m     )\n\u001b[1;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/chat_models/openai.py:360\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    359\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[0;32m--> 360\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(\n\u001b[1;32m    361\u001b[0m     messages\u001b[39m=\u001b[39;49mmessage_dicts, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    362\u001b[0m )\n\u001b[1;32m    363\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/chat_models/openai.py:299\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/langchain/chat_models/openai.py:297\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-FL5W5***************************************SRgJ. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import itemgetter\n",
    "from typing import List, Tuple\n",
    "from langchain.globals import set_verbose\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage, format_document\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import (\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    "    RunnableMap,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from pydantic import BaseModel, Field\n",
    "set_verbose(True)\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"  # noqa: E501\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "# RAG answer synthesis prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Conversational Retrieval Chain\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        print(f\"human{human}, ai:{ai}\")\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    print(buffer)\n",
    "    return buffer\n",
    "\n",
    "\n",
    "# User input\n",
    "class ChatHistory(BaseModel):\n",
    "    chat_history: List[Tuple[str, str]]\n",
    "    question: str\n",
    "\n",
    "\n",
    "_search_query = RunnableBranch(\n",
    "    # If input includes chat_history, we condense it with the follow-up question\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "            run_name=\"HasChatHistoryCheck\"\n",
    "        ),  # Condense follow-up question and chat into a standalone_question\n",
    "        RunnablePassthrough.assign(\n",
    "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        )\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | ChatOpenAI(temperature=0)\n",
    "        | StrOutputParser(),\n",
    "    ),\n",
    "    # Else, we have no chat history, so just pass through the question\n",
    "    RunnableLambda(itemgetter(\"question\")),\n",
    ")\n",
    "\n",
    "_inputs = RunnableMap(\n",
    "    {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: _format_chat_history(x[\"chat_history\"]),\n",
    "        \"context\": _search_query | retriever | _combine_documents,\n",
    "    }\n",
    ").with_types(input_type=ChatHistory)\n",
    "openai_llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://aiapi.xing-yun.cn/v1\",\n",
    "    openai_api_key=\"sk-3e5wTBAl2iFDvQvW9b5693C90a97425eBf3b4bEa558eC66a\",\n",
    "    temperature=0.1,\n",
    "    model_name=\"gpt-4\",\n",
    ")\n",
    "chain = _inputs | ANSWER_PROMPT | llm | StrOutputParser()\n",
    "\n",
    "chat_history = [(\"hi\", \"hello\")]\n",
    "answer = chain.invoke(\n",
    "    {\n",
    "        \"question\":question,\n",
    "        \"chat_history\":[(\"hi\",\"AIMessage\")]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n 在雷电天气下，民航飞机的飞行风险增加，这对民航飞行安全提出了挑战。根据提供的背景资料，我们可以了解到以下几点：\\n\\n1. 雷雨天气对飞机飞行的影响：雷雨天气会对民航飞行产生负面影响，如降低飞行稳定性、增大飞行误差、引发设备故障等，从而增加飞行安全风险。\\n\\n2. 民航飞行中雷电天气的安全事故比例较高：据统计，民航在飞行过程中因雷电天气而出现的安全事故在所有安全事故中占比较高，这进一步强调了加强雷电天气下民航飞行安全研究的必要性。\\n\\n3. 现有防雷技术及措施存在不足：针对雷电天气下民航飞机的飞行风险，目前采用的防雷技术和措施仍存在一定的局限性，需要不断研究和改进。\\n\\n因此，在雷电天气下民航飞机的飞行风险及预防措施分析中，我们需要对这些问题进行深入研究，以期提出有效的解决方案，保障民航飞行安全。'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 在雷电天气下，民航飞机的飞行风险增加，这对民航飞行安全提出了挑战。根据提供的背景资料，我们可以了解到以下几点：\n",
      "\n",
      "1. 雷雨天气对飞机飞行的影响：雷雨天气会对民航飞行产生负面影响，如降低飞行稳定性、增大飞行误差、引发设备故障等，从而增加飞行安全风险。\n",
      "\n",
      "2. 民航飞行中雷电天气的安全事故比例较高：据统计，民航在飞行过程中因雷电天气而出现的安全事故在所有安全事故中占比较高，这进一步强调了加强雷电天气下民航飞行安全研究的必要性。\n",
      "\n",
      "3. 现有防雷技术及措施存在不足：针对雷电天气下民航飞机的飞行风险，目前采用的防雷技术和措施仍存在一定的局限性，需要不断研究和改进。\n",
      "\n",
      "因此，在雷电天气下民航飞机的飞行风险及预防措施分析中，我们需要对这些问题进行深入研究，以期提出有效的解决方案，保障民航飞行安全。\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
