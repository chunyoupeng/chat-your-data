{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from chat_paper.query_data import *\n",
    "from langchain.schema import HumanMessage\n",
    "print(get_llm)\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "# llm([HumanMessage(content=\"给我讲一个长故事\")])\n",
    "local_llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    openai_api_base=\"http://localhost:8001/v1\",\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"tell me a story\")]\n",
    "out = local_llm(messages)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out.content)\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# llm([HumanMessage(content=\"给我讲一个长故事\")])\n",
    "glm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    openai_api_base=\"http://localhost:8001/v1\",\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    temperature=0.1,\n",
    "    # max_tokens=6999\n",
    "    # streaming=True,\n",
    "    # callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "messages = [HumanMessage(content=\"卡尔曼波是什么\")]\n",
    "glm_out = glm(messages)\n",
    "glm_out\n",
    "# len(glm_out.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.callbacks.streaming_stdout import  StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.manager import  CallbackManager\n",
    "llm = ChatOllama(\n",
    "    model=\"yi:34b-chat\",\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"给我讲一个毛主席的故事\")]\n",
    "llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai_llm_3 = ChatOpenAI(\n",
    "    openai_api_base=\"https://aiapi.xing-yun.cn/v1\",\n",
    "    openai_api_key=\"sk-Ny6WUAgn9PQCOMqQ0d9a0174Ba9e45348862D2746aF44923\",\n",
    "    temperature=0.3,\n",
    "    model_name=\"gpt-4-1106-preview\",\n",
    "    # streaming=True,  # ! important\n",
    "    # callbacks=[StreamingStdOutCallbackHandler()]  # ! important\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = openai_llm_3([HumanMessage(content=\"给我讲一个长故事\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='故事的名字叫做《迷失的王国》。\\n\\n在一个遥远的世界里，有一个叫做阿斯特拉的王国。这个王国是由一个强大的国王，亚历山大统治的。他是一个公正而又仁慈的国王，他的人民都非常尊敬他。然而，他有一个秘密，那就是他的王冠。这个王冠有一个神奇的力量，它可以保护阿斯特拉王国免受任何外来的侵害。\\n\\n然而，有一天，王冠突然消失了。没有了王冠的保护，阿斯特拉王国开始受到邻近的敌对国家的侵犯。国王亚历山大决定派他的儿子，亚瑟去寻找这个王冠。\\n\\n亚瑟是一个勇敢而又聪明的年轻人，他接受了父亲的任务，踏上了寻找王冠的旅程。他穿过了森林，越过了山脉，渡过了河流。在他的旅途中，他遇到了各种各样的困难，但他都没有放弃。\\n\\n在他的旅途中，他遇到了一位名叫艾米莉的女孩。艾米莉是一个美丽而又善良的女孩，她决定帮助亚瑟寻找王冠。他们一起经历了许多冒险，也一起度过了许多困难。\\n\\n在他们的旅途中，他们发现了一个古老的传说。传说中，王冠被一个邪恶的巫师偷走了，他用王冠的力量来统治世界。亚瑟和艾米莉决定一起去对抗这个邪恶的巫师。\\n\\n经过一场激烈的战斗，他们成功的打败了邪恶的巫师，取回了王冠。他们带着王冠回到了阿斯特拉王国，国王亚历山大和他的人民都非常高兴。\\n\\n从此，阿斯特拉王国再也没有受到过任何的侵犯，亚瑟和艾米莉也成为了人民心中的英雄。他们的故事被人们传颂着，成为了阿斯特拉王国的一部分。\\n\\n这个故事告诉我们，只要我们有勇气去面对困难，有决心去实现我们的目标，我们就一定能够成功。'\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the model path is correct for your system!\n",
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"../../models/openbuddy-zephyr-7b-v14.1.Q5_K_M.gguf\",\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=False,  # Verbose is required to pass to the callback manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm(\"write python code to qsort fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"yi:34b-chat\", \n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "    temperature=0.3,\n",
    "    num_ctx=8000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm(\"我是一个5岁的孩子，给我讲懂AI的历史，2000字\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
